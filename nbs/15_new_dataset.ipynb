{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import zeus.notebook_utils.syspath as syspath\n",
    "syspath.add_parent_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import rasterio\n",
    "from kidney.datasets.kaggle import get_reader, SampleType, DatasetReader\n",
    "from zeus.core.random import super_seed\n",
    "from zeus.utils import list_files\n",
    "from zeus.plotting.utils import axes, calculate_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(reader: DatasetReader, sample_type: SampleType):\n",
    "    reader = get_reader()\n",
    "    train_keys = reader.get_keys(sample_type)\n",
    "    identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "    for key in train_keys:\n",
    "        meta = reader.fetch_meta(key)\n",
    "        with rasterio.open(meta[\"tiff\"], transform=identity) as dataset:\n",
    "            height, width = shape = dataset.shape\n",
    "            has_mask = \"[trn]\" if meta[\"mask\"] is not None else \"[tst]\"\n",
    "            print(has_mask, key, height, width, dataset.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset_info(get_reader(), SampleType.All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARED_DIR = \"/mnt/fast/data/kidney/images_32_1024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png_images(folder: str):\n",
    "    samples = defaultdict(dict)\n",
    "    for fn in list_files(folder):\n",
    "        image_type, image_id = Path(fn).stem.split(\".\")\n",
    "        samples[image_id][image_type] = fn\n",
    "        if image_type == \"img\":\n",
    "            samples[image_id][\"masked\"] = False\n",
    "            samples[image_id][\"colored\"] = colored_image(fn)\n",
    "        if image_type == \"seg\":\n",
    "            samples[image_id][\"masked\"] = True\n",
    "            samples[image_id][\"mask_image_ratio\"] = non_zero_pixels_ratio(fn)\n",
    "    return samples\n",
    "        \n",
    "def colored_image(filename: str) -> bool:\n",
    "    image = PIL.Image.open(filename)\n",
    "    return image.mode == \"RGB\"\n",
    "\n",
    "def non_zero_pixels_ratio(filename: str) -> float:\n",
    "    arr = np.asarray(PIL.Image.open(filename))\n",
    "    return np.where(arr == 255, 1, 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = read_png_images(PREPARED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14\n",
    "keys = random.sample(images.keys(), k=n*n)\n",
    "canvas = axes(subplots=(n, n), figsize=(30, 30))\n",
    "decode = {}\n",
    "for i, (key, ax) in enumerate(zip(keys, canvas.flat)):\n",
    "    img = PIL.Image.open(images[key][\"img\"])\n",
    "    ax.imshow(img, cmap=None if images[key][\"colored\"] else \"gray\")\n",
    "    ax.axis(False)\n",
    "    ax.set_title(f\"{i}\")\n",
    "    decode[i] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors = (3, 25, 42, 54, 57, 60, 64, 104, 135)\n",
    "# anchors = (0, 11, 19, 56, 81, 91, 101, 122, 178, 195)\n",
    "# anchors = (81, 0, 11, 91, 101, 6, 149)\n",
    "anchors = (149, 91, 101, 81, 109, 93)\n",
    "n = len(anchors)\n",
    "canvas = axes(subplots=(1, n), figsize=(18, 4))\n",
    "filenames = []\n",
    "for i, ax in enumerate(canvas.flat):\n",
    "    path = images[decode[anchors[i]]][\"img\"]\n",
    "    filenames.append(path)\n",
    "    img = PIL.Image.open(path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(False)\n",
    "    ax.set_title(anchors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorTransfer:\n",
    "    \n",
    "    def __init__(self, mean: np.ndarray, std: np.ndarray, ref: str = \"default\"):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.ref = ref\n",
    "        \n",
    "    @staticmethod\n",
    "    def read_json(filename: str):\n",
    "        with open(filename, \"r\") as fp:\n",
    "            contents = json.load(fp)\n",
    "        mean = [np.array(c) for c in contents[\"mean\"]]\n",
    "        std = [np.array(c) for c in contents[\"std\"]]\n",
    "        return ColorTransfer(mean, std)\n",
    "    \n",
    "    def write_json(self, filename: str):\n",
    "        with open(filename, \"w\") as fp:\n",
    "            json.dump({\n",
    "                \"mean\": [c.tolist() for c in self.mean], \n",
    "                \"std\": [c.tolist() for c in self.std],\n",
    "                \"reference\": self.ref\n",
    "            }, fp)\n",
    "    \n",
    "    def transfer_image(self, target: np.ndarray, as_rgb: bool = True):\n",
    "        channels = []\n",
    "        for i, channel in enumerate(cv.split(target)):\n",
    "            channel -= channel.mean()\n",
    "            channel *= channel.std()/(self.std[i] + 1e-8)\n",
    "            channel += self.mean[i]\n",
    "            channel = channel.clip(0, 255)\n",
    "            channels.append(channel)\n",
    "        image = cv.merge(channels).astype(np.uint8)\n",
    "        if as_rgb:\n",
    "            image = cv.cvtColor(image, cv.COLOR_LAB2RGB)\n",
    "        return image\n",
    "            \n",
    "\n",
    "def read_lab(filename: str):\n",
    "    bgr = cv.imread(filename)\n",
    "    lab = cv.cvtColor(bgr, cv.COLOR_BGR2LAB).astype(np.float32)\n",
    "    return lab\n",
    "\n",
    "\n",
    "def channel_stats(image: np.ndarray):\n",
    "    channels = cv.split(image)\n",
    "    mean = [c.mean() for c in channels]\n",
    "    std = [c.std() for c in channels]\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "n = len(filenames)\n",
    "canvas = axes(subplots=(n, n), figsize=(n*3, n*3))\n",
    "output_dir = \"/mnt/fast/data/color_transfers\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for i in range(n):\n",
    "    lab = read_lab(filenames[i])\n",
    "    mean, std = channel_stats(lab)\n",
    "    t = ColorTransfer(mean, std, filenames[i])\n",
    "    image_id = Path(filenames[i]).stem.split(\".\")[-1]\n",
    "    t.write_json(os.path.join(output_dir, f\"{image_id}.json\"))\n",
    "    for j in range(n):\n",
    "        index = i*n + j\n",
    "        transferred = t.transfer_image(read_lab(filenames[j]))\n",
    "        canvas.flat[index].imshow(transferred)\n",
    "        canvas.flat[index].axis(False)\n",
    "        if i == j:\n",
    "            canvas.flat[index].set_title(anchors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1 {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "json_files = [os.path.join(output_dir, fn) for fn in os.listdir(output_dir)]\n",
    "n = len(filenames)\n",
    "canvas = axes(subplots=(n, n), figsize=(n*3, n*3))\n",
    "for i in range(n):\n",
    "    lab = read_lab(filenames[i])\n",
    "    mean, std = channel_stats(lab)\n",
    "    t = ColorTransfer.read_json(json_files[i])\n",
    "    for j in range(n):\n",
    "        index = i*n + j\n",
    "        transferred = t.transfer_image(read_lab(filenames[j]))\n",
    "        canvas.flat[index].imshow(transferred)\n",
    "        canvas.flat[index].axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Groups Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_summary(images: Dict) -> pd.DataFrame:\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            \"image_id\": image_id,\n",
    "            \"masked\": info[\"masked\"],\n",
    "            \"colored\": info[\"colored\"],\n",
    "            \"ratio\": info[\"mask_image_ratio\"] if info[\"masked\"] else np.nan,\n",
    "        }\n",
    "        for image_id, info in images.items()\n",
    "    ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = images_summary(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored = info.query(\"colored\")\n",
    "colored_no_mask = colored.query(\"ratio == 0\")\n",
    "colored_small_mask = colored.query(\"ratio > 0 and ratio <= 0.05\")\n",
    "colored_medium_mask = colored.query(\"ratio > 0.05 and ratio <= 0.20\")\n",
    "colored_large_mask = colored.query(\"ratio > 0.20\")\n",
    "\n",
    "grayscale = info.query(\"not colored\")\n",
    "grayscale_no_mask = grayscale.query(\"ratio == 0\")\n",
    "grayscale_small_mask = grayscale.query(\"ratio > 0 and ratio <= 0.05\")\n",
    "grayscale_medium_mask = grayscale.query(\"ratio > 0.05 and ratio <= 0.20\")\n",
    "grayscale_large_mask = grayscale.query(\"ratio > 0.20\")\n",
    "\n",
    "image_groups = {\n",
    "    \"colored\": {\n",
    "        \"empty\": colored_no_mask.image_id.tolist(),\n",
    "        \"small\": colored_small_mask.image_id.tolist(),\n",
    "        \"medium\": colored_medium_mask.image_id.tolist(),\n",
    "        \"large\": colored_large_mask.image_id.tolist(),\n",
    "    },\n",
    "    \"grayscale\": {\n",
    "        \"empty\": grayscale_no_mask.image_id.tolist(),\n",
    "        \"small\": grayscale_small_mask.image_id.tolist(),\n",
    "        \"medium\": grayscale_medium_mask.image_id.tolist(),\n",
    "        \"large\": grayscale_medium_mask.image_id.tolist(),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info.query(\"colored\").ratio.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info.query(\"not colored\").ratio.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (\n",
    "    colored,\n",
    "    colored_no_mask,\n",
    "    colored_small_mask,\n",
    "    colored_medium_mask,\n",
    "    colored_large_mask,\n",
    "    grayscale,\n",
    "    grayscale_no_mask,\n",
    "    grayscale_small_mask,\n",
    "    grayscale_medium_mask,\n",
    "    grayscale_large_mask,\n",
    "):\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "for color, mask_groups in image_groups.items():\n",
    "    for mask_size, image_ids in mask_groups.items():\n",
    "        keys = random.sample(image_ids, k=n*n)\n",
    "        canvas = axes(subplots=(n, n), figsize=(20, 20))\n",
    "        for key, ax in zip(keys, canvas.flat):\n",
    "            x = images[key]\n",
    "            img = np.asarray(PIL.Image.open(x[\"img\"]))\n",
    "            seg = np.asarray(PIL.Image.open(x[\"seg\"]))\n",
    "            grayscale = img.ndim == 2\n",
    "            ax.imshow(img, cmap=\"gray\" if color == \"grayscale\" else None)\n",
    "            ax.imshow(seg, alpha=0.3)\n",
    "            ax.axis(False)\n",
    "            # ax.set_title(\"grayscale\" if grayscale else \"colored\")\n",
    "        plt.gcf().suptitle(f\"{color} ({mask_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = samples[\"8242609fa_19584_10759_20608_11783\"]\n",
    "# img = np.asarray(PIL.Image.open(x[\"img\"]))\n",
    "# seg = np.asarray(PIL.Image.open(x[\"seg\"]))\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(img)\n",
    "# plt.imshow(seg, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 7\n",
    "# keys = random.sample(samples.keys(), k=n*n)\n",
    "# canvas = axes(subplots=(n, n), figsize=(20, 20))\n",
    "# for key, ax in zip(keys, canvas.flat):\n",
    "#     x = samples[key]\n",
    "#     img = np.asarray(PIL.Image.open(x[\"img\"]))\n",
    "#     seg = np.asarray(PIL.Image.open(x[\"seg\"]))\n",
    "#     grayscale = img.ndim == 2\n",
    "#     ax.imshow(img, cmap=\"gray\" if grayscale else None)\n",
    "#     ax.imshow(seg, alpha=0.3)\n",
    "#     ax.axis(False)\n",
    "#     ax.set_title(\"grayscale\" if grayscale else \"colored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kidney.datasets.offline import create_data_loaders\n",
    "from kidney.datasets.transformers import get_transformers, IntensityNormalization\n",
    "from kidney.datasets.utils import read_segmentation_info\n",
    "from pytorch_lightning.utilities import AttributeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = get_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = reader.get_keys(SampleType.Labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys, valid_keys = train_keys[:-1], train_keys[-1]\n",
    "train_keys, valid_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transformers??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = get_transformers(AttributeDict(\n",
    "    aug_pipeline=\"strong\",\n",
    "    aug_normalization_method=IntensityNormalization.TorchvisionSegmentation,\n",
    "    dataset=PREPARED_DIR,\n",
    "    model_input_size=1024,\n",
    "    model_input_image_key=\"img\",\n",
    "    model_input_mask_key=\"seg\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_segmentation_info(PREPARED_DIR, file_format=\"bbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = create_data_loaders(\n",
    "    reader=reader,\n",
    "    valid_keys=[valid_keys],\n",
    "    transformers=transformers,\n",
    "    samples=samples,\n",
    "    num_workers=0,\n",
    "    batch_size=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loaders[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kidney (3.7)",
   "language": "python",
   "name": "kidney"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
