{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import zeus.notebook_utils.syspath as syspath\n",
    "syspath.add_parent_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from IPython.display import display\n",
    "from rasterio.windows import Window\n",
    "from zeus.utils import home\n",
    "from zeus.plotting.utils import axes\n",
    "from kidney.experiments.aug import get_dataset_input_size\n",
    "from kidney.datasets.kaggle import outlier, get_reader, DatasetReader, SampleType\n",
    "from kidney.experiments import FCNExperiment\n",
    "from kidney.inference.inference import SlidingWindow, SlidingWindowConfig\n",
    "from kidney.inference.window import sliding_window_boxes\n",
    "from kidney.utils.tiff import read_tiff\n",
    "from kidney.utils.mask import rle_decode, rle_numba_encode\n",
    "from kidney.utils.plotting import preview_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMIT_DIR = \"/mnt/fast/kaggle/submits/kidney\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = \"aug\"\n",
    "TIMESTAMP = \"Wed_06_Jan__18_19_20\"\n",
    "WEIGHTS = \"epoch=6_avg_val_loss=0.1043.ckpt\"\n",
    "CHECKPOINT_PATH = os.path.join(SUBMIT_DIR, \"fcn_resnet50_e6_avl1043_w1024_o32_sz256_expo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:1\")\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_paths(\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    weights: str\n",
    "):\n",
    "    dirname = home(f\"experiments/{experiment}/checkpoints/{timestamp}\")\n",
    "    info_filename = os.path.join(dirname, \"info.pth\")\n",
    "    weights_filename = os.path.join(dirname, weights)\n",
    "    return info_filename, weights_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(\n",
    "    info_filename: str,\n",
    "    weights_filename: str,\n",
    "    factory: pl.LightningModule,\n",
    "    overlap: int,\n",
    "    max_batch_size: int,\n",
    "    check_for_outliers: bool,\n",
    "    device: torch.device = DEVICE,\n",
    "    debug: bool = False\n",
    "):\n",
    "    meta = torch.load(info_filename)\n",
    "    meta[\"params\"][\"fcn_pretrained\"] = False\n",
    "    meta[\"params\"][\"fcn_pretrained_backbone\"] = False\n",
    "    experiment = factory.load_from_checkpoint(\n",
    "        weights_filename, \n",
    "        params=meta[\"params\"], \n",
    "        strict=False\n",
    "    )\n",
    "    transformers = meta[\"transformers\"]\n",
    "    inference = SlidingWindow(\n",
    "        model=experiment.eval().to(device),\n",
    "        config=SlidingWindowConfig(\n",
    "            window_size=get_dataset_input_size(meta[\"params\"][\"dataset\"]),\n",
    "            overlap=overlap,\n",
    "            max_batch_size=max_batch_size,\n",
    "            check_for_outliers=check_for_outliers,\n",
    "            transform_input=transformers.test_preprocessing,\n",
    "            transform_output=transformers.test_postprocessing\n",
    "        ),\n",
    "        device=device,\n",
    "        debug=debug\n",
    "    )\n",
    "    return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = get_inference(\n",
    "    *get_checkpoint_paths(\n",
    "        experiment=EXPERIMENT,\n",
    "        timestamp=TIMESTAMP,\n",
    "        weights=WEIGHTS\n",
    "    ),\n",
    "    factory=FCNExperiment,\n",
    "    overlap=32,\n",
    "    max_batch_size=50,\n",
    "    check_for_outliers=True,\n",
    "    debug=DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = get_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type = SampleType.Unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inference.predict_from_reader(reader, sample_type, encoder=rle_numba_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.columns = [\"id\", \"predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_type == SampleType.Unlabeled:\n",
    "    predictions_df.to_csv(CHECKPOINT_PATH, index=False)\n",
    "    print(\"saved:\", CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small-Scale Predictions Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeus.plotting.utils import calculate_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 1024\n",
    "total = predictions_df.shape[0]\n",
    "n, m = calculate_layout(total, n_cols=3)\n",
    "grid = axes(subplots=(n, m), figsize=(30, 40))\n",
    "\n",
    "for ax in grid.flat:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "for i in range(total):\n",
    "    record = predictions_df.iloc[i]\n",
    "    meta = reader.fetch_meta(record.id)\n",
    "    tiff = read_tiff(meta[\"tiff\"])\n",
    "    y_pred = rle_decode(record.predicted, tiff.shape)\n",
    "    if meta.get(\"mask\") is not None:\n",
    "        y_true = rle_decode(meta[\"mask\"], tiff.shape)\n",
    "    else:\n",
    "        y_true = None\n",
    "    tiff, y_pred, y_true = [\n",
    "        cv.resize(arr, (sz, sz)) \n",
    "        if arr is not None \n",
    "        else arr \n",
    "        for arr in (tiff, y_pred, y_true)]\n",
    "    ax = grid.flat[i]\n",
    "    preview_arrays(tiff, gt=y_true, pred=y_pred, ax=ax)\n",
    "    ax.set_title(record.id, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large-Scale Predictions Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(key: str):\n",
    "    global reader, inference\n",
    "    meta = reader.fetch_meta(key)\n",
    "    full_size_image = read_tiff(meta[\"tiff\"])\n",
    "    mask_true = rle_decode(meta[\"mask\"], full_size_image.shape)\n",
    "    mask_pred = inference.predict_from_file(meta[\"tiff\"])\n",
    "    return full_size_image, mask_true, mask_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THUMB_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(\n",
    "    image: np.ndarray, \n",
    "    mask_true: np.ndarray,\n",
    "    mask_pred: np.ndarray, \n",
    "    thumb_size: int = THUMB_SIZE,\n",
    "    ax=None, \n",
    "    **fig_params\n",
    "):\n",
    "    ax = axes(ax=ax, **fig_params)\n",
    "    thumb_img, thumb_gt, thumb_pred = [\n",
    "        cv.resize(arr, (thumb_size, thumb_size)) \n",
    "        for arr in (image, mask_true, mask_pred)\n",
    "    ]\n",
    "    preview_arrays(thumb_img, thumb_gt, thumb_pred, ax=ax)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_keys:\n",
    "    img, y_true, y_pred = predict(key)\n",
    "    ax = preview(img, y_true, y_pred, figsize=(30, 30))\n",
    "    ax.set_title(key, fontsize=20)\n",
    "    display(ax.figure)\n",
    "    ax.figure.savefig(f\"/mnt/fast/data/{key}.png\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kidney (3.7)",
   "language": "python",
   "name": "kidney"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
